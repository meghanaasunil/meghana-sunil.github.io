---
layout: default
---
<div class="home other-pages">

<h1 class="page-heading">Research</h1>

<div class="row">
    <div class="col-md-12">
        <p>My research focuses on machine learning, domain generalization, and multimodal representation learning. Below are my research projects and publications.</p>
    </div>
</div>

<div>&nbsp;</div>

<h2>In Progress</h2>

<ul>
<li><h4>Contrastive Learning Under Domain Shift: Do Positive Pairs Help or Hurt Robustness?</h4> 
  <i>In Progress</i> | Advisor: Dr. Joe Dhanith <br>
  • Investigating how positive pairs in contrastive learning frameworks (SimCLR, MoCo-v2, BYOL) impact robustness across domain shifts using leave-one-out evaluation on PACS, Office-Home and Terra Incognita benchmarks.<br>
  • Analyzing representation quality of self-supervised models under domain generalization scenarios, identifying key limitations in conventional augmentation strategies that lead to sub-35% accuracy on unseen domains.<br>
  • Developing novel positive/negative pair formulations to improve cross-domain generalization while preserving representation quality in visual recognition tasks.
  </li>
</ul>

<ul>
<li><h4>A Lightweight Continual Learning Approach via Retrieval-Augmented Generation for Personalized AI Assistants</h4> 
  <i>In Progress</i> | Advisor: Dr. Joe Dhanith <br>
  • Proposing a continual learning framework that utilizes Retrieval-Augmented Generation (RAG) to improve assistant personalization, achieving over 87% accuracy in intent-aware response generation.<br>
  • Designing a modular memory-augmented architecture that enhances long-term personalization via external retrieval, showing a 24% increase in personalization quality through continual learning.<br>
  • Optimizing for low-resource deployment by reducing retraining overhead and improving response relevance, leading to a projected 33% increase in user satisfaction across task-based assistant interactions.
  </li>
</ul>

<div>&nbsp;</div>

<h2>Submitted</h2>

<ul>
<li><h4>Graph-Guided Cross-Modal Representation Learning of EEG–fNIRS via Spatio-Temporal Transformers for Stress Analysis</h4> 
  <i>Submitted: Computer Methods and Programs in Biomedicine</i> | Advisor: Dr. Jeetashree Aparajeeta <br>
  • Proposed CM-GGT, a cross-modal gated fusion framework integrating a spectrogram-transformer EEG encoder, a graph neural network fNIRS encoder, and a dual-stage fusion module with cross-attention and adaptive gating.<br>
  • Achieved 93.2% accuracy and 0.967 AUC on simultaneous EEG–fNIRS recordings from 26 participants across cognitive tasks (n-back, digit symbol recognition, word generation), outperforming 11 state-of-the-art baselines.<br>
  • Demonstrated fine-grained modeling of neural–hemodynamic interactions, with adaptive weighting of modality contributions to mitigate signal-specific noise and enhance robustness.<br>
  • Conducted ablation and interpretability analyses confirming the contribution of each architectural component and revealing task-dependent modality adaptation consistent with established neurophysiological patterns.
  </li>
</ul>

<ul>
<li><h4>Rethinking Knowledge Retrieval for Generation: A Survey on RAG Architectures and Applications</h4> 
  <i>Submitted: Artificial Intelligence Review</i> | Advisor: Dr. Joe Dhanith <br>
  • Conducting a comprehensive review of Retrieval-Augmented Generation (RAG) systems, analyzing the latest innovations and advancements in the field.<br>
  • Introducing a four-tier taxonomy for classifying RAG architectures, systematically evaluating their strengths, limitations, and impact on retrieval and generation performance.<br>
  • Curating and categorizing eight key applications of RAGs, providing a structured overview of their real-world impact across healthcare, legal AI, finance, and more.
  </li>
</ul>

<div>&nbsp;</div>

<h2>Published</h2>

<ul>
<li><h4>Encouraging Discriminative Attention Through Contrastive Explainability Learning for Lung Cancer Diagnosis</h4> 
  <i>IEEE Access</i> | Advisor: Dr. Natarajan B <br>
  • Developed a novel Contrastive Explainability Learning (CEL) framework for lung cancer classification, achieving >98% accuracy and F1-score on the IQ-OTH/NCCD dataset.<br>
  • Optimizing a hybrid loss with explainability constraints, experimenting with λ values from 0.1 to 1.0 to balance classification performance and Grad-CAM consistency.<br>
  • Enforcing self-supervised Grad-CAM contrastive constraints in CNNs to enhance feature attribution and discriminative attention in medical imaging.<br>
  [<a href="#">Paper</a>] [<a href="#">Code</a>]
  </li>
</ul>

<ul>
<li><h4>Self-Attentive Quantile GAN with Causally Grounded Machine Learning for Vocal Biomarker Discovery in Parkinson's Disease Detection</h4> 
  <i>IEEE Access</i> | Advisor: Dr. Nachiyappan S <br>
  • Developed a novel framework integrating causal inference with voice analysis, leveraging vocal frequency spread as a key biomarker for Parkinson's disease detection.<br>
  • Implemented a directed acyclic graph (DAG) framework to estimate the Average Treatment Effect (ATE), ensuring reliable causal interpretations in high-dimensional data.<br>
  • Achieved 95.03% precision and an AUC-ROC of 97.84%, outperforming traditional machine learning models while improving interpretability with CatBoost-based causal modeling.<br>
  [<a href="#">Paper</a>] [<a href="#">Code</a>]
  </li>
</ul>

<div>&nbsp;</div>

<h2>Architecture</h2>
<div class="row">
    <div class="col-md-12">
        <img src="/assets/img/research/architecture.jpg" alt="Research Architecture" style="max-width: 100%; height: auto;">
    </div>
</div>

</div>

