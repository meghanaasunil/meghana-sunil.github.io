<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Research – Meghana Sunil</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      max-width: 900px;
      margin: 40px auto;
      padding: 0 16px 64px;
      font-size: 16px;
      line-height: 1.6;
      color: #111;
      background: #fff;
    }

    a {
      color: #0366d6;
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

    h1, h2, h3 {
      font-weight: 600;
      line-height: 1.3;
    }

    h1 {
      font-size: 2rem;
      margin-bottom: 0.25rem;
    }

    h2 {
      margin-top: 2.5rem;
      margin-bottom: 1rem;
      font-size: 1.35rem;
    }

    h3 {
      margin: 0 0 0.5rem;
      font-size: 1.05rem;
    }

    p {
      margin: 0.15rem 0 0.5rem;
    }

    ul {
      padding-left: 1.1rem;
      margin: 0.25rem 0 0.5rem;
    }

    li {
      margin-bottom: 0.35rem;
    }

    .muted {
      color: #555;
    }

    .site-header {
      display: flex;
      flex-wrap: wrap;
      align-items: baseline;
      justify-content: space-between;
      margin-bottom: 2rem;
      gap: 0.75rem;
    }

    .site-title a {
      font-weight: 700;
      font-size: 1.1rem;
      color: inherit;
      text-decoration: none;
    }

    .site-nav a {
      margin-left: 0.75rem;
      font-size: 0.95rem;
    }

    .site-nav .active {
      font-weight: 600;
      text-decoration: underline;
      text-underline-offset: 4px;
    }

    .section-note {
      font-size: 0.9rem;
      color: #666;
      margin-top: -0.25rem;
      margin-bottom: 0.75rem;
    }

    /* Research cards */
    .research-list {
      display: flex;
      flex-direction: column;
      gap: 2.5rem;
    }

    .research-item {
      display: flex;
      gap: 1.5rem;
      align-items: flex-start;
    }

    .research-thumb {
      flex: 0 0 180px;
      max-width: 180px;
    }

    .research-thumb img {
      width: 100%;
      border-radius: 10px;
      border: 1px solid #eee;
      object-fit: cover;
    }

    .research-content {
      flex: 1 1 auto;
      min-width: 0;
    }

    .research-meta {
      font-size: 0.9rem;
      color: #555;
      margin-bottom: 0.35rem;
    }

    .research-links {
      font-size: 0.9rem;
      margin-top: 0.35rem;
    }

    .badge {
      display: inline-block;
      font-size: 0.8rem;
      padding: 2px 6px;
      border-radius: 999px;
      border: 1px solid #ddd;
      margin-left: 0.35rem;
      color: #555;
    }

    @media (max-width: 700px) {
      .research-item {
        flex-direction: column;
      }
      .research-thumb {
        max-width: 100%;
      }
    }
  </style>
</head>
<body>

  <!-- Header / nav -->
  <header class="site-header">
    <div class="site-title">
      <a href="/">Meghana Sunil</a>
    </div>
    <nav class="site-nav">
      <a href="/">Home</a>
      <a href="/research.html" class="active">Research</a>
      <a href="/blog.html">Blog</a>
      <a href="/misc.html">Misc</a>
    </nav>
  </header>

  <main>
    <h1>Research</h1>
    <p class="muted">
      I’m broadly interested in machine learning, domain generalization, multimodal representation learning,
      and applied neuroinformatics. Below is a selection of my ongoing and completed research projects.
    </p>

    <!-- Ongoing & Core ML Research -->
    <h2>Ongoing & Core ML Research</h2>
    <div class="research-list">

      <!-- Contrastive Learning under Domain Shift -->
      <article class="research-item">
        <div class="research-thumb">
          <!-- Replace src with your actual image file -->
          <img src="images/domain-shift-contrastive.png" alt="Contrastive learning under domain shift visualization">
        </div>
        <div class="research-content">
          <h3>Contrastive Learning Under Domain Shift: Do Positive Pairs Help or Hurt Robustness?</h3>
          <p class="research-meta">
            <strong>Meghana Sunil</strong>
            <span class="badge">in progress</span>
          </p>
          <p class="muted">
            Self-supervised contrastive learning methods such as SimCLR, MoCo-v2, and BYOL achieve strong performance
            on in-domain data, but their behavior under domain shifts is still not fully understood.
          </p>
          <ul>
            <li>Study the effect of positive pair design and augmentations on robustness across domains (PACS, Office-Home, Terra Incognita).</li>
            <li>Analyze how implicit assumptions about invariances impact cross-domain generalization.</li>
            <li>Explore alternative positive/negative sampling strategies tailored for domain generalization.</li>
          </ul>
          <p class="research-links muted">
            paper (coming soon) · code (coming soon)
          </p>
        </div>
      </article>

      <!-- Continual Learning via RAG -->
      <article class="research-item">
        <div class="research-thumb">
          <img src="images/rag-continual-learning.png" alt="Diagram of retrieval-augmented continual learning">
        </div>
        <div class="research-content">
          <h3>A Lightweight Continual Learning Approach via Retrieval-Augmented Generation for Personalized AI Assistants</h3>
          <p class="research-meta">
            <strong>Meghana Sunil</strong>
            <span class="badge">in progress</span>
          </p>
          <p class="muted">
            Personalized AI assistants must adapt to evolving user preferences without expensive full-model retraining.
            This project explores RAG-based continual learning to maintain a persistent, user-specific memory.
          </p>
          <ul>
            <li>Design a memory store and retriever to capture long-term user behavior and preferences.</li>
            <li>Use parameter-efficient fine-tuning and RAG instead of frequent full fine-tunes.</li>
            <li>Evaluate on personalization benchmarks focusing on stability, adaptation speed, and memory usage.</li>
          </ul>
          <p class="research-links muted">
            paper (coming soon) · code (coming soon)
          </p>
        </div>
      </article>

      <!-- RAG Survey -->
      <article class="research-item">
        <div class="research-thumb">
          <img src="images/rag-survey.png" alt="Taxonomy of retrieval-augmented generation systems">
        </div>
        <div class="research-content">
          <h3>Rethinking Knowledge Retrieval for Generation: A Survey on RAG Architectures and Applications</h3>
          <p class="research-meta">
            <strong>Meghana Sunil</strong>
            <span class="badge">under review</span>
          </p>
          <p class="muted">
            A survey of retrieval-augmented generation (RAG) systems, covering retrievers, generators, and memory
            modules, with a focus on practical deployment in high-stakes domains.
          </p>
          <ul>
            <li>Propose a taxonomy of RAG architectures spanning dense, sparse, and hybrid retrieval.</li>
            <li>Review applications in healthcare, legal AI, finance, and conversational systems.</li>
            <li>Discuss open challenges around hallucinations, latency, and retrieval robustness.</li>
          </ul>
          <p class="research-links muted">
            manuscript (in preparation)
          </p>
        </div>
      </article>
    </div>

    <!-- Medical AI & Neuroinformatics -->
    <h2>Medical AI &amp; Neuroinformatics</h2>
    <div class="research-list">

      <!-- EEG–fNIRS Stress Analysis -->
      <article class="research-item">
        <div class="research-thumb">
          <img src="images/eeg-fnirs-stress.png" alt="EEG–fNIRS cross-modal stress analysis architecture">
        </div>
        <div class="research-content">
          <h3>Graph-Guided Cross-Modal Representation Learning of EEG–fNIRS via Spatio-Temporal Transformers for Stress Analysis</h3>
          <p class="research-meta">
            <strong>Meghana Sunil</strong> · Center for Neuroinformatics, VIT Chennai
            <span class="badge">submitted</span>
          </p>
          <p class="muted">
            CM-GGT: a cross-modal gated fusion framework for stress classification using simultaneous EEG–fNIRS recordings.
          </p>
          <ul>
            <li>Encode EEG using spectrogram-based temporal transformers and fNIRS using graph neural networks.</li>
            <li>Fuse modalities through cross-modal gating to capture complementary temporal–spatial patterns.</li>
            <li>Achieve strong performance and provide channel-level interpretability for neurophysiological analysis.</li>
          </ul>
          <p class="research-links muted">
            manuscript (under review) · code (coming soon)
          </p>
        </div>
      </article>

      <!-- Lung Cancer CEL (IEEE Access) -->
      <article class="research-item">
        <div class="research-thumb">
          <img src="images/lung-cancer-cel.png" alt="Contrastive explainability learning for lung cancer diagnosis">
        </div>
        <div class="research-content">
          <h3>Encouraging Discriminative Attention Through Contrastive Explainability Learning for Lung Cancer Diagnosis</h3>
          <p class="research-meta">
            <strong>Meghana Sunil</strong> · IEEE Access · Advisor: Nachiyappan S
          </p>
          <p class="muted">
            Contrastive Explainability Learning (CEL) enforces Grad-CAM–based contrastive constraints so that models
            focus on truly discriminative regions in CT images while maintaining high classification accuracy.
          </p>
          <ul>
            <li>Formulate a contrastive loss over explanation maps rather than only predictions.</li>
            <li>Encourage separation between relevant and irrelevant regions for each class.</li>
            <li>Demonstrate improvements on lung cancer diagnosis benchmarks without sacrificing performance.</li>
          </ul>
          <p class="research-links muted">
            <a href="https://ieeexplore.ieee.org/abstract/document/11184753" target="_blank">paper</a> ·
            code (coming soon)
          </p>
        </div>
      </article>

      <!-- Parkinson’s Disease Vocal Biomarkers (IEEE Access) -->
      <article class="research-item">
        <div class="research-thumb">
          <img src="images/parkinsons-vocal-gan.png" alt="Self-attentive quantile GAN for Parkinson’s disease detection">
        </div>
        <div class="research-content">
          <h3>Self-Attentive Quantile GAN with Causally Grounded Machine Learning for Vocal Biomarker Discovery in Parkinson’s Disease Detection</h3>
          <p class="research-meta">
            <strong>Meghana Sunil</strong> · IEEE Access · Advisor: Natarajan B
          </p>
          <p class="muted">
            A self-attentive Quantile GAN paired with causal inference to study vocal frequency spread as a biomarker
            for Parkinson’s disease, targeting robust detection under distributional variability.
          </p>
          <ul>
            <li>Build a generative model to capture heterogeneous vocal patterns in patient and control groups.</li>
            <li>Use causal graphs (DAGs) to estimate treatment effects and control for confounders.</li>
            <li>Report high diagnostic metrics and interpretability for vocal biomarkers.</li>
          </ul>
          <p class="research-links muted">
            <a href="https://ieeexplore.ieee.org/document/11113240" target="_blank">paper</a> ·
            code (coming soon)
          </p>
        </div>
      </article>
    </div>

    <!-- Closing note -->
    <h2>Where Research Meets Practice</h2>
    <p class="muted">
      Beyond these projects, I enjoy building systems where research ideas meet real-world constraints—such as
      quantized deep learning models for edge devices and RAG-based interfaces integrated into web applications.
      Some of these applied projects appear on my <a href="/">home page</a>.
    </p>
  </main>

</body>
</html>
